{
  "version": 1,
  "enabled": true,
  "endpoints": [
    {
      "id": "local-main",
      "base_url": "http://127.0.0.1:1234/v1",
      "role": "primary",
      "enabled": true,
      "max_parallel": 4
    },
    {
      "id": "lan-86",
      "base_url": "http://192.168.50.86:1234/v1",
      "role": "throughput",
      "enabled": true,
      "max_parallel": 4
    },
    {
      "id": "lan-91",
      "base_url": "http://192.168.50.91:1234/v1",
      "role": "coder",
      "enabled": true,
      "max_parallel": 4
    },
    {
      "id": "lan-238",
      "base_url": "http://192.168.50.238:1234/v1",
      "role": "reasoning",
      "enabled": true,
      "max_parallel": 4
    }
  ],
  "routing": {
    "local_first": true,
    "saturate_local_before_hosted": true,
    "complexity_thresholds": {
      "simple": 25,
      "standard": 45,
      "complex": 70
    },
    "complexity_preferences": {
      "simple": [
        "liquid/lfm2.5-1.2b",
        "google/gemma-3-4b"
      ],
      "standard": [
        "qwen/qwen2.5-coder-32b",
        "deepseek-coder-v2-lite-instruct"
      ],
      "complex": [
        "qwen/qwen3-coder-next",
        "meta/llama-3.3-70b"
      ],
      "deep_research": [
        "meta/llama-3.3-70b",
        "deepseek-r1-distill-llama-70b"
      ]
    }
  },
  "target_models": [
    "liquid/lfm2.5-1.2b",
    "google/gemma-3-4b",
    "deepseek/deepseek-r1-0528-qwen3-8b",
    "deepseek-coder-v2-lite-instruct",
    "qwen/qwen2.5-coder-32b",
    "qwen/qwen3-coder-next"
  ],
  "benchmark": {
    "timeout_sec": 20,
    "max_tokens": 220,
    "temperature": 0,
    "models_per_endpoint": 4,
    "probe_ttl_sec": 60,
    "prompt": "Return compact JSON with keys: ok(boolean), lane_type(string), rationale(string <= 80 chars)."
  },
  "capability_scan": {
    "enabled": true,
    "timeout_sec": 12,
    "max_parallel_probe": 8,
    "success_rate_threshold": 0.8,
    "latency_guard_ratio": 0.95,
    "probe_max_tokens": 48,
    "probe_temperature": 0,
    "probe_prompt": "Reply with exactly OK.",
    "preferred_models": [
      "liquid/lfm2.5-1.2b",
      "google/gemma-3-4b",
      "qwen/qwen2.5-coder-32b",
      "meta/llama-3.3-70b"
    ],
    "complexity_preference": [
      "standard",
      "simple",
      "complex",
      "deep_research"
    ],
    "context_model_preference": [
      "qwen/qwen2.5-coder-32b",
      "meta/llama-3.3-70b",
      "google/gemma-3-4b"
    ],
    "context_token_steps": [
      1024,
      4096,
      8192,
      16384
    ],
    "context_probe_max_tokens": 8
  },
  "download_command_template": ""
}
